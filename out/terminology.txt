3:I[5613,[],""]
4:I[1778,[],""]
5:I[5351,["250","static/chunks/250-de05d05c403bb79c.js","185","static/chunks/app/layout-b33843260b5cb8a2.js"],""]
0:["JKorZx7B9s2Q-F6y1_ngf",[[["",{"children":["terminology",{"children":["__PAGE__",{}]}]},"$undefined","$undefined",true],["",{"children":["terminology",{"children":["__PAGE__",{},["$L1","$L2",null]]},["$","$L3",null,{"parallelRouterKey":"children","segmentPath":["children","terminology","children"],"loading":"$undefined","loadingStyles":"$undefined","loadingScripts":"$undefined","hasLoading":false,"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L4",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","notFoundStyles":"$undefined","styles":[["$","link","0",{"rel":"stylesheet","href":"/mcag/_next/static/css/f5656361e6e0e6a1.css","precedence":"next","crossOrigin":""}]]}]]},[null,["$","html",null,{"lang":"en","children":["$","body",null,{"className":"__className_dbd9d9","children":[["$","$L5",null,{}],["$","$L3",null,{"parallelRouterKey":"children","segmentPath":["children"],"loading":"$undefined","loadingStyles":"$undefined","loadingScripts":"$undefined","hasLoading":false,"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L4",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":[["$","title",null,{"children":"404: This page could not be found."}],["$","div",null,{"style":{"fontFamily":"system-ui,\"Segoe UI\",Roboto,Helvetica,Arial,sans-serif,\"Apple Color Emoji\",\"Segoe UI Emoji\"","height":"100vh","textAlign":"center","display":"flex","flexDirection":"column","alignItems":"center","justifyContent":"center"},"children":["$","div",null,{"children":[["$","style",null,{"dangerouslySetInnerHTML":{"__html":"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}"}}],["$","h1",null,{"className":"next-error-h1","style":{"display":"inline-block","margin":"0 20px 0 0","padding":"0 23px 0 0","fontSize":24,"fontWeight":500,"verticalAlign":"top","lineHeight":"49px"},"children":"404"}],["$","div",null,{"style":{"display":"inline-block"},"children":["$","h2",null,{"style":{"fontSize":14,"fontWeight":400,"lineHeight":"49px","margin":0},"children":"This page could not be found."}]}]]}]}]],"notFoundStyles":[],"styles":null}]]}]}],null]],[[["$","link","0",{"rel":"stylesheet","href":"/mcag/_next/static/css/446b0b6c530aaf25.css","precedence":"next","crossOrigin":""}]],"$L6"]]]]
6:[["$","meta","0",{"name":"viewport","content":"width=device-width, initial-scale=1"}],["$","meta","1",{"charSet":"utf-8"}],["$","title","2",{"children":"Terminology"}],["$","meta","3",{"name":"description","content":"Generated by create next app"}],["$","link","4",{"rel":"icon","href":"/mcag/favicon.ico","type":"image/x-icon","sizes":"16x16"}],["$","meta","5",{"name":"next-size-adjust"}]]
1:null
7:I[6038,["250","static/chunks/250-de05d05c403bb79c.js","782","static/chunks/782-00febb50443a01e9.js","81","static/chunks/app/terminology/page-eacae1718739b790.js"],""]
c:I[1749,["250","static/chunks/250-de05d05c403bb79c.js","782","static/chunks/782-00febb50443a01e9.js","81","static/chunks/app/terminology/page-eacae1718739b790.js"],"Image"]
8:Tad4,<h4>Complex</h4><p>Complex images refer to visuals that contain intricate or detailed content, such as diagrams, charts, graphs, or illustrations with multifaceted information. Text alternatives for complex images aim to provide a concise yet comprehensive description that conveys the crucial information within the image. It should offer a textual representation of the image's content, structure, and relationships between various elements within the visual, ensuring that users relying on screen readers or other assistive technologies can grasp the essential details presented by the complex image. This text alternative intends to offer an equivalent understanding of the image's information without overwhelming the user with excessive details.</p><h4>Decorative</h4><p>Decorative images refer to images that serve a solely aesthetic or decorative purpose, providing no significant content or information relevant to understanding the app's functionality or content. Text alternatives for decorative images are typically left empty or use a null value, indicating to assistive technologies that the image is purely decorative and does not convey any meaningful information necessary for understanding the app's content or functionality. This approach helps screen readers focus on essential content without disrupting the user experience with irrelevant descriptions for purely ornamental visuals.</p><h4>Functional</h4><p>Functional images refer to images that represent controls, links, or buttons essential for users to interact with the app's functionality. Text alternatives for functional images should convey the function or purpose of the control, aiding users who rely on screen readers or assistive technologies to understand the interactive nature of the image. This alt text should succinctly describe the action or outcome triggered by interacting with the image, ensuring users comprehend its role in the app's functionality. Providing accurate text alternatives for functional images is crucial for users who rely on assistive technologies to navigate and interact effectively within the mobile application.</p><h4>Informative</h4><p>Informative images are images that convey essential information, context, or conveyance of function within the app's interface. Text alternatives for informative images are descriptive text alternatives that succinctly describe the content or message conveyed by the image, aiding users who rely on screen readers or other assistive technologies to understand the significance of the visual element. The text alternatives for informative images should be informative and concise. They should clearly represent the image's purpose or content to ensure users receive the relevant information conveyed by the image.</p>9:T452,<p>In the context of mobile applications, the term "media" refers to various types of content that can be embedded or integrated into the app to enhance its visual or auditory experience. Media elements can be, for example, a static image, a video audio-only or audio-only tracks, or synchronized tracks that include both video and audio.</p><p>Since media elements, by nature, are oriented to the user's sensory receptors (primarily visual or auditory), their content must have an alternative that can be perceived by all users and read programmatically by assistive technologies.</p><p>Because of the diversity of media types and their nature, the alternative type may differ between different media types. In addition, because media alternatives must provide a solution for people with a variety of impairments, sometimes more than one alternative is required to ensure that all users can accurately perceive the entire media content.</p><p>See also: <a href='#static-media'>Static media</a>, <a href='#time-based-media'>Time-based media</a>, and <a href='#synchronized-media'>Synchronized media</a></p>a:T49e,<p>The term "Role" refers to the type of component or widget an element represents on a webpage or native app, like a button, link, heading, or menu.</p><p>Web and native platforms build roles into native components. Using these components will provide "out of the box" support of the essential attributes required by the component type, such as support of states, returning a value, and the implied behavior of the component type.</p><p>Custom components use dedicated attributes to define the component’s role. Platforms have specific attributes for these roles so that assistive technologies interpret the component correctly.</p><p>The component’s role is separate from its accessible name. A component’s role is not added to the accessible name because assistive technologies may not correctly identify it for users.</p><p>Web and native app platforms usually have a dedicated attribute when defining custom roles or types. Custom roles typically use familiar and unambiguous terms that reflect the nature of the component and how it is used. Custom roles are uncommon and used sparingly on custom components as most roles can be defined through dedicated attributes.</p>b:T462,<p>Text alternatives refer to descriptive text or content provided alongside visual elements such as images, graphics, or media (audio or video) to ensure that users, particularly those using screen readers or other assistive technologies, can access and comprehend the content. These text alternatives convey the essential information presented by the visual content, enabling users who cannot perceive the visual elements to understand their purpose, function, or information conveyed, thus fostering a more inclusive and accessible mobile app experience.</p><p>Since images and graphic elements may have different roles and purposes (such as an icon on a button, adding information to the written text, or graphs and charts). The phrasing of the text alternative should optimally serve the purpose and content that the image represents. An excellent place to learn about the optimal ways to formulate text alternatives is the <a href='https://www.w3.org/WAI/tutorials/images/'>W3C's Images Tutorial</a>, which also includes a decision tree to help users determine what text alternative fits specific use cases best.</p>d:Tad4,<h4>Complex</h4><p>Complex images refer to visuals that contain intricate or detailed content, such as diagrams, charts, graphs, or illustrations with multifaceted information. Text alternatives for complex images aim to provide a concise yet comprehensive description that conveys the crucial information within the image. It should offer a textual representation of the image's content, structure, and relationships between various elements within the visual, ensuring that users relying on screen readers or other assistive technologies can grasp the essential details presented by the complex image. This text alternative intends to offer an equivalent understanding of the image's information without overwhelming the user with excessive details.</p><h4>Decorative</h4><p>Decorative images refer to images that serve a solely aesthetic or decorative purpose, providing no significant content or information relevant to understanding the app's functionality or content. Text alternatives for decorative images are typically left empty or use a null value, indicating to assistive technologies that the image is purely decorative and does not convey any meaningful information necessary for understanding the app's content or functionality. This approach helps screen readers focus on essential content without disrupting the user experience with irrelevant descriptions for purely ornamental visuals.</p><h4>Functional</h4><p>Functional images refer to images that represent controls, links, or buttons essential for users to interact with the app's functionality. Text alternatives for functional images should convey the function or purpose of the control, aiding users who rely on screen readers or assistive technologies to understand the interactive nature of the image. This alt text should succinctly describe the action or outcome triggered by interacting with the image, ensuring users comprehend its role in the app's functionality. Providing accurate text alternatives for functional images is crucial for users who rely on assistive technologies to navigate and interact effectively within the mobile application.</p><h4>Informative</h4><p>Informative images are images that convey essential information, context, or conveyance of function within the app's interface. Text alternatives for informative images are descriptive text alternatives that succinctly describe the content or message conveyed by the image, aiding users who rely on screen readers or other assistive technologies to understand the significance of the visual element. The text alternatives for informative images should be informative and concise. They should clearly represent the image's purpose or content to ensure users receive the relevant information conveyed by the image.</p>e:T452,<p>In the context of mobile applications, the term "media" refers to various types of content that can be embedded or integrated into the app to enhance its visual or auditory experience. Media elements can be, for example, a static image, a video audio-only or audio-only tracks, or synchronized tracks that include both video and audio.</p><p>Since media elements, by nature, are oriented to the user's sensory receptors (primarily visual or auditory), their content must have an alternative that can be perceived by all users and read programmatically by assistive technologies.</p><p>Because of the diversity of media types and their nature, the alternative type may differ between different media types. In addition, because media alternatives must provide a solution for people with a variety of impairments, sometimes more than one alternative is required to ensure that all users can accurately perceive the entire media content.</p><p>See also: <a href='#static-media'>Static media</a>, <a href='#time-based-media'>Time-based media</a>, and <a href='#synchronized-media'>Synchronized media</a></p>f:T49e,<p>The term "Role" refers to the type of component or widget an element represents on a webpage or native app, like a button, link, heading, or menu.</p><p>Web and native platforms build roles into native components. Using these components will provide "out of the box" support of the essential attributes required by the component type, such as support of states, returning a value, and the implied behavior of the component type.</p><p>Custom components use dedicated attributes to define the component’s role. Platforms have specific attributes for these roles so that assistive technologies interpret the component correctly.</p><p>The component’s role is separate from its accessible name. A component’s role is not added to the accessible name because assistive technologies may not correctly identify it for users.</p><p>Web and native app platforms usually have a dedicated attribute when defining custom roles or types. Custom roles typically use familiar and unambiguous terms that reflect the nature of the component and how it is used. Custom roles are uncommon and used sparingly on custom components as most roles can be defined through dedicated attributes.</p>10:T462,<p>Text alternatives refer to descriptive text or content provided alongside visual elements such as images, graphics, or media (audio or video) to ensure that users, particularly those using screen readers or other assistive technologies, can access and comprehend the content. These text alternatives convey the essential information presented by the visual content, enabling users who cannot perceive the visual elements to understand their purpose, function, or information conveyed, thus fostering a more inclusive and accessible mobile app experience.</p><p>Since images and graphic elements may have different roles and purposes (such as an icon on a button, adding information to the written text, or graphs and charts). The phrasing of the text alternative should optimally serve the purpose and content that the image represents. An excellent place to learn about the optimal ways to formulate text alternatives is the <a href='https://www.w3.org/WAI/tutorials/images/'>W3C's Images Tutorial</a>, which also includes a decision tree to help users determine what text alternative fits specific use cases best.</p>2:["$","main",null,{"className":"$undefined","children":[["$","h1",null,{"children":"Terminology"}],["$","div",null,{"className":"terminology_terminologyWrapper__8zG8D","children":[["$","$L7",null,{"data":{"a":[{"title":"Accessible name","text":"<p>An accessible name, often referred to as an 'accessibility identifier' or 'accessibility label,' is a text attribute associated with a UI (User Interface) element in a mobile app. This label provides information about the purpose or nature of the UI element. It is crucial to make the app accessible to users who rely on assistive technologies.</p><p>Examples of UI components that require an accessible name include but are not limited to buttons, links, form elements, and UI controls.</p><p>The importance of accessibility labels lies in their role in making mobile apps usable for individuals with visual or cognitive impairments. Users who rely on screen readers, voice commands, or other assistive technologies depend on these labels to understand and interact with the app's interface.</p><p>The content of accessibility labels should be clear, concise, and descriptive. It should convey the essential information about the UI element's purpose without being overly verbose.</p>","images":[]},{"title":"Accessibility Navigation Menus (on Screen Readers)","text":"<p>\"Screen Readers' Accessibility Navigation Menus\" encompasses interface components or controls typically available in screen readers, such as VoiceOver Rotor in iOS or TalkBack Reading Control in Android. These menus offer users customizable tools and options to navigate interfaces effectively. They provide shortcuts, settings adjustments, and navigation controls tailored for accessibility needs, enhancing user interaction and enabling seamless access to digital content on various devices.</p>","images":[{"name":"ios-nav-menu.png","alt":"The VoiceOver Rotor set on Speaking Rate","caption":"VoiceOver Rotor","height":"130","width":"130"},{"name":"android-nav-menu.png","alt":"The TalkBack Reading control set on Headings","caption":"TalkBack Reading control","height":"130","width":"130"}]},{"title":"Audio descriptions","text":"<p>Audio descriptions, also known as descriptive audio or video descriptions, are spoken narrations that provide additional information about visual content. These descriptions are specifically designed to assist individuals who are blind or visually impaired in comprehending visual elements that are not otherwise conveyed through dialogue or sound.</p><p>Audio descriptions verbally convey essential visual elements, such as actions, settings, gestures, scene changes, and expressions, which are not evident from the audio track alone. They are typically inserted during natural pauses in dialogue or sound elements to avoid interrupting the original audio content. They integrate seamlessly with the audio or video, ensuring a cohesive viewing or listening experience.</p><p>Audio descriptions are commonly found in TV shows, movies, educational videos, and cultural events. They can be provided as a separate audio track or through specialized devices and services.</p>","images":[]}],"b":[],"c":[{"title":"Captions","text":"<p>Captions are text-based representations of the audio content in a video, audio, or multimedia presentation. They display the spoken dialogue, sound effects, and other auditory information as text on the screen, synchronized with the corresponding visuals.</p><p>There are two types of captions. The first type is the Closed Captions (CC). This caption type is not embedded into the media file and can be toggled on and off. Open Captions are permanently embedded into the video and cannot be turned off. They are always visible when the video is played.</p><p>Captions play a crucial role in making multimedia content accessible, providing an alternative means of understanding the auditory information presented in videos and ensuring a more inclusive experience for all viewers.</p>","images":[]}],"d":[],"e":[{"title":"Essential content","text":"<p>\"Essential content\" refers to critical information necessary to understand or operate the UI. Without it, users may have difficulty or be unable to perceive the content's context and purpose or operating controls.</p>","images":[]}],"f":[{"title":"Full justify (text alignment)","text":"<p>\"Full justify\" alignment is a type of text alignment where the text block's left and right sides are aligned evenly. In full justify alignment, spaces between words and characters are adjusted dynamically to ensure that each line of text reaches both the left and right margins of the text block, creating a neat and straight edge on both sides.</p><p>This alignment style can enhance the visual appeal of text, presenting a clean and formal appearance. However, it can occasionally create uneven spacing between words, which might affect readability, especially in narrow columns or when dealing with irregular word lengths. In terms of accessibility, full justify alignment might pose challenges for users with dyslexia or visual impairments, as uneven spacing can make it more difficult to track lines while reading.</p>","images":[]},{"title":"Focus indication","text":"<p>Focus indication is a visual cue or indicator that highlights the currently focused element on the screen when using the app. It is critical to make apps accessible to users who navigate through interfaces using assistive technologies like voice control or keyboard navigation.</p><p>The focus indication helps users understand where they are within the app and which element will respond to their input next as they navigate through interactive elements.</p><p>Effective focus indication provides a clear and intuitive user experience for those who rely on keyboard navigation or other assistive technologies, ensuring equal access to app functionality for all users.</p>","images":[]},{"title":"Focus sequence","text":"<p>Focus sequence refers to the order in which interactive elements or controls receive focus when using navigation methods like keyboard navigation or other input methods. It denotes the logical flow or sequence in which these elements are selected or activated as users navigate the app's interface. A well-organized focus sequence ensures that the focus order aligns with the app's structure and content flow, allowing users to navigate and interact with app elements coherently and predictably. This is particularly crucial for users relying on keyboard navigation or assistive technologies to access and interact with mobile app interfaces.</p>","images":[]}],"g":[],"h":[],"i":[{"title":"Images of text","text":"Images of text refer to readable content essential for comprehending the content and its context presented within and as a part of an image media.","images":[]},{"title":"Image types","text":"$8","images":[]}],"j":[],"k":[],"l":[],"m":[{"title":"Media","text":"$9","images":[]},{"title":"Multipoint gestures","text":"Multipoint gestures involve interactions on a touchscreen using multiple contact points simultaneously, typically using more than one finger.<br />These gestures typically involve using two or more fingers or touch points on the screen simultaneously to perform actions or trigger specific functionalities within the app.<br/>When offering advanced interaction methods, developers should ensure these gestures are intuitive, discoverable for users, and provide alternatives for individuals with motor limitations or other disabilities.","images":[]}],"n":[],"o":[],"p":[{"title":"Path-based gestures","text":"<p>Path-based gestures refer to actions in the application that require users to draw or trace specific paths, shapes, or gestures on the screen following predefined patterns recognized by the app.<br />Path-based gestures often enable custom or specialized actions beyond standard tapping or swiping, allowing users to interact with the app uniquely. However, when offering non-standard interaction methods, developers must ensure these gestures are intuitive and accessible to users with diverse abilities, providing alternative methods for those who might find tracing gestures challenging.</p>","images":[]},{"title":"Points (measurement unit)","text":"<p>\"Points\" refers to a measurement unit used typically to determine text size. Points are a standard unit of measurement for font size where 1 point (pt) is approximately equal to 1/72 of an inch.</p><p>On iOS, font size is usually measured with points. For example, <code>UIFont</code> in iOS uses point sizes for text.</p><p>Android, however, uses \"scaled pixels\" (sp). To calculate points from scaled pixels, use this formula:</p><p><code>points = scaledPixels / displayDensity</code></p><p>Where <code>scaledPixels</code> is the text size in \"<code>sp</code>\", and displayDensity is the device's screen density.</p>","images":[]},{"title":"Programmatically read/determined","text":"<p>This term refers to content that user agents, like assistive technologies, can extract, interpret, and present to users in different modalities.</p>","images":[]}],"q":[],"r":[{"title":"Reading sequence","text":"<p>Reading sequence refers to the programmatic order of elements in the UI, as assistive technologies such as screen readers interpret and read them.</p>","images":[]},{"title":"Real-time updates","text":"<p>Real-time updates refer to information that dynamically and continuously refreshes and displays changing data or statuses to users. These updates provide current, up-to-the-moment details on a particular event, process, or status relevant to the user's interaction with the application.</p><p>Real-time updates provide users with information that directly impacts their current interaction or experience with the application. For instance, in a delivery app, real-time updates might display the estimated time of arrival (ETA) or the current location of the delivery person.</p><p>A few examples of application types that commonly use real-time updates are public transportation apps, food delivery services, stock market updates, and more.</p><p>In essence, real-time updates in applications serve to keep users informed and engaged by continuously delivering timely and relevant information about ongoing processes or events, enriching the overall user experience.</p>","images":[]},{"title":"Role","text":"$a","images":[]}],"s":[{"title":"Single-pointer gestures","text":"<p>Single-pointer gestures are a single point of contact, typically using one-finger interactions like a tap or double-tap that perform actions or trigger specific functionalities within the app's interface. These gestures are often the primary input method for users with a variety of disabilities. Developers must ensure they are responsive and compatible with assistive technologies.</p>","images":[]},{"title":"Static media","text":"<p>\"Static media\" refers to non-text content that doesn't change or progress over time (like audio or video tracks would). Examples of static media include images, infographics, diagrams, or other non-text elements that do not rely on a time-based sequence for comprehension.</p><p>See also: <a href='#media'>Media</a>, <a href='#time-based-media'>Time-based media</a>, and <a href='#synchronized-media'>Synchronized media</a></p>","images":[]},{"title":"Synchronized media","text":"<p>\"Synchronized media\" refers to a video track with a synchronized corresponding audio track that auditory reflects the actions on the video.</p><p>See also: <a href='#media'>Media</a>, <a href='#static-media'>Static media</a>, and <a href='#time-based-media'>Time-based media</a></p>","images":[]}],"t":[{"title":"Text blocks","text":"<p>Text blocks refer to sections or segments of textual content. They typically contain at least three full rows of text in the app's body text font size.</p>","images":[]},{"title":"Text alternatives","text":"$b","images":[]},{"title":"Time-based media","text":"<p>\"Time-based media\" refers to non-text content that unfolds or changes over time, such as audio or video files. These media types inherently have a duration and evolve as the content progresses, presenting the information within a specific timeframe.</p><p>See also: <a href='#media'>Media</a>, <a href='#static-media'>Static media</a>, and <a href='#synchronized-media'>Synchronized media</a></p>","images":[]},{"title":"Time-sensitive updates","text":"<p>\"Time-sensitive\" updates refer to information or notifications that require immediate attention or action from the user within a specific timeframe. These updates are designed to convey important or critical information with urgency or a limited window of time.</p><p>Time-sensitive updates convey information that requires prompt user action or attention. The information of time-sensitive updates could be related to security alerts, critical reminders, or real-time changes in a situation (e.g., location-based alerts). Time-sensitive notifications are often crucial for the user to maintain an app's service's functionality, security, or timeliness. For example, notifications about account security breaches or transaction verifications are time-sensitive due to their critical nature.</p>","images":[]},{"title":"","text":"<p></p>","images":[]},{"title":"Toasts","text":"<p>\"Toasts\" are small, non-modal messages that provide user feedback, notifications, or alerts. Toast messages are typically displayed for a limited time before they automatically disappear. The fact that Toast messages are non-modal means that they don't require user interaction to dismiss them, and assistive technologies should announce their content without shifting focus to them.</p><p>Toast messages serve as unobtrusive, transient notifications or feedback mechanisms that inform users about specific events, updates, or actions within the app interface without disrupting the user experience.</p>","images":[]},{"title":"Transcript","text":"<p>A transcript is a written or typed record of spoken words, dialogue, or text from a specific audio or video file. It represents a textual version of the content spoken or presented within the audio or video recording.</p><p>Unlike captions, transcripts do not provide descriptions of other relevant sounds. Transcripts can be time-indexed but are not synchronized with their associated audio or video tracks.</p>","images":[]}],"u":[],"v":[],"w":[],"x":[],"y":[],"z":[]}}],["$","div",null,{"className":"terminology_contentWrapper__HUR4y","children":[["$","section","a",{"children":[["$","h2",null,{"children":"A"}],[["$","article","accessible-name",{"children":[["$","h3",null,{"id":"accessible-name","children":"Accessible name"}],["$","div",null,{"dangerouslySetInnerHTML":{"__html":"<p>An accessible name, often referred to as an 'accessibility identifier' or 'accessibility label,' is a text attribute associated with a UI (User Interface) element in a mobile app. This label provides information about the purpose or nature of the UI element. It is crucial to make the app accessible to users who rely on assistive technologies.</p><p>Examples of UI components that require an accessible name include but are not limited to buttons, links, form elements, and UI controls.</p><p>The importance of accessibility labels lies in their role in making mobile apps usable for individuals with visual or cognitive impairments. Users who rely on screen readers, voice commands, or other assistive technologies depend on these labels to understand and interact with the app's interface.</p><p>The content of accessibility labels should be clear, concise, and descriptive. It should convey the essential information about the UI element's purpose without being overly verbose.</p>"}}],false]}],["$","article","accessibility-navigation-menus-on-screen-readers",{"children":[["$","h3",null,{"id":"accessibility-navigation-menus-on-screen-readers","children":"Accessibility Navigation Menus (on Screen Readers)"}],["$","div",null,{"dangerouslySetInnerHTML":{"__html":"<p>\"Screen Readers' Accessibility Navigation Menus\" encompasses interface components or controls typically available in screen readers, such as VoiceOver Rotor in iOS or TalkBack Reading Control in Android. These menus offer users customizable tools and options to navigate interfaces effectively. They provide shortcuts, settings adjustments, and navigation controls tailored for accessibility needs, enhancing user interaction and enabling seamless access to digital content on various devices.</p>"}}],[["$","div","ios-nav-menu.png",{"className":"terminology_imageWrapper__aHTYf","children":[["$","$Lc",null,{"src":"/images/ios-nav-menu.png","alt":"The VoiceOver Rotor set on Speaking Rate","height":"130","width":"130"}],["$","span",null,{"aria-hidden":"true","style":{"maxWidth":"130px"},"children":"VoiceOver Rotor"}]]}],["$","div","android-nav-menu.png",{"className":"terminology_imageWrapper__aHTYf","children":[["$","$Lc",null,{"src":"/images/android-nav-menu.png","alt":"The TalkBack Reading control set on Headings","height":"130","width":"130"}],["$","span",null,{"aria-hidden":"true","style":{"maxWidth":"130px"},"children":"TalkBack Reading control"}]]}]]]}],["$","article","audio-descriptions",{"children":[["$","h3",null,{"id":"audio-descriptions","children":"Audio descriptions"}],["$","div",null,{"dangerouslySetInnerHTML":{"__html":"<p>Audio descriptions, also known as descriptive audio or video descriptions, are spoken narrations that provide additional information about visual content. These descriptions are specifically designed to assist individuals who are blind or visually impaired in comprehending visual elements that are not otherwise conveyed through dialogue or sound.</p><p>Audio descriptions verbally convey essential visual elements, such as actions, settings, gestures, scene changes, and expressions, which are not evident from the audio track alone. They are typically inserted during natural pauses in dialogue or sound elements to avoid interrupting the original audio content. They integrate seamlessly with the audio or video, ensuring a cohesive viewing or listening experience.</p><p>Audio descriptions are commonly found in TV shows, movies, educational videos, and cultural events. They can be provided as a separate audio track or through specialized devices and services.</p>"}}],false]}]]]}],"$undefined",["$","section","c",{"children":[["$","h2",null,{"children":"C"}],[["$","article","captions",{"children":[["$","h3",null,{"id":"captions","children":"Captions"}],["$","div",null,{"dangerouslySetInnerHTML":{"__html":"<p>Captions are text-based representations of the audio content in a video, audio, or multimedia presentation. They display the spoken dialogue, sound effects, and other auditory information as text on the screen, synchronized with the corresponding visuals.</p><p>There are two types of captions. The first type is the Closed Captions (CC). This caption type is not embedded into the media file and can be toggled on and off. Open Captions are permanently embedded into the video and cannot be turned off. They are always visible when the video is played.</p><p>Captions play a crucial role in making multimedia content accessible, providing an alternative means of understanding the auditory information presented in videos and ensuring a more inclusive experience for all viewers.</p>"}}],false]}]]]}],"$undefined",["$","section","e",{"children":[["$","h2",null,{"children":"E"}],[["$","article","essential-content",{"children":[["$","h3",null,{"id":"essential-content","children":"Essential content"}],["$","div",null,{"dangerouslySetInnerHTML":{"__html":"<p>\"Essential content\" refers to critical information necessary to understand or operate the UI. Without it, users may have difficulty or be unable to perceive the content's context and purpose or operating controls.</p>"}}],false]}]]]}],["$","section","f",{"children":[["$","h2",null,{"children":"F"}],[["$","article","full-justify-text-alignment",{"children":[["$","h3",null,{"id":"full-justify-text-alignment","children":"Full justify (text alignment)"}],["$","div",null,{"dangerouslySetInnerHTML":{"__html":"<p>\"Full justify\" alignment is a type of text alignment where the text block's left and right sides are aligned evenly. In full justify alignment, spaces between words and characters are adjusted dynamically to ensure that each line of text reaches both the left and right margins of the text block, creating a neat and straight edge on both sides.</p><p>This alignment style can enhance the visual appeal of text, presenting a clean and formal appearance. However, it can occasionally create uneven spacing between words, which might affect readability, especially in narrow columns or when dealing with irregular word lengths. In terms of accessibility, full justify alignment might pose challenges for users with dyslexia or visual impairments, as uneven spacing can make it more difficult to track lines while reading.</p>"}}],false]}],["$","article","focus-indication",{"children":[["$","h3",null,{"id":"focus-indication","children":"Focus indication"}],["$","div",null,{"dangerouslySetInnerHTML":{"__html":"<p>Focus indication is a visual cue or indicator that highlights the currently focused element on the screen when using the app. It is critical to make apps accessible to users who navigate through interfaces using assistive technologies like voice control or keyboard navigation.</p><p>The focus indication helps users understand where they are within the app and which element will respond to their input next as they navigate through interactive elements.</p><p>Effective focus indication provides a clear and intuitive user experience for those who rely on keyboard navigation or other assistive technologies, ensuring equal access to app functionality for all users.</p>"}}],false]}],["$","article","focus-sequence",{"children":[["$","h3",null,{"id":"focus-sequence","children":"Focus sequence"}],["$","div",null,{"dangerouslySetInnerHTML":{"__html":"<p>Focus sequence refers to the order in which interactive elements or controls receive focus when using navigation methods like keyboard navigation or other input methods. It denotes the logical flow or sequence in which these elements are selected or activated as users navigate the app's interface. A well-organized focus sequence ensures that the focus order aligns with the app's structure and content flow, allowing users to navigate and interact with app elements coherently and predictably. This is particularly crucial for users relying on keyboard navigation or assistive technologies to access and interact with mobile app interfaces.</p>"}}],false]}]]]}],"$undefined","$undefined",["$","section","i",{"children":[["$","h2",null,{"children":"I"}],[["$","article","images-of-text",{"children":[["$","h3",null,{"id":"images-of-text","children":"Images of text"}],["$","div",null,{"dangerouslySetInnerHTML":{"__html":"Images of text refer to readable content essential for comprehending the content and its context presented within and as a part of an image media."}}],false]}],["$","article","image-types",{"children":[["$","h3",null,{"id":"image-types","children":"Image types"}],["$","div",null,{"dangerouslySetInnerHTML":{"__html":"$d"}}],false]}]]]}],"$undefined","$undefined","$undefined",["$","section","m",{"children":[["$","h2",null,{"children":"M"}],[["$","article","media",{"children":[["$","h3",null,{"id":"media","children":"Media"}],["$","div",null,{"dangerouslySetInnerHTML":{"__html":"$e"}}],false]}],["$","article","multipoint-gestures",{"children":[["$","h3",null,{"id":"multipoint-gestures","children":"Multipoint gestures"}],["$","div",null,{"dangerouslySetInnerHTML":{"__html":"Multipoint gestures involve interactions on a touchscreen using multiple contact points simultaneously, typically using more than one finger.<br />These gestures typically involve using two or more fingers or touch points on the screen simultaneously to perform actions or trigger specific functionalities within the app.<br/>When offering advanced interaction methods, developers should ensure these gestures are intuitive, discoverable for users, and provide alternatives for individuals with motor limitations or other disabilities."}}],false]}]]]}],"$undefined","$undefined",["$","section","p",{"children":[["$","h2",null,{"children":"P"}],[["$","article","path-based-gestures",{"children":[["$","h3",null,{"id":"path-based-gestures","children":"Path-based gestures"}],["$","div",null,{"dangerouslySetInnerHTML":{"__html":"<p>Path-based gestures refer to actions in the application that require users to draw or trace specific paths, shapes, or gestures on the screen following predefined patterns recognized by the app.<br />Path-based gestures often enable custom or specialized actions beyond standard tapping or swiping, allowing users to interact with the app uniquely. However, when offering non-standard interaction methods, developers must ensure these gestures are intuitive and accessible to users with diverse abilities, providing alternative methods for those who might find tracing gestures challenging.</p>"}}],false]}],["$","article","points-measurement-unit",{"children":[["$","h3",null,{"id":"points-measurement-unit","children":"Points (measurement unit)"}],["$","div",null,{"dangerouslySetInnerHTML":{"__html":"<p>\"Points\" refers to a measurement unit used typically to determine text size. Points are a standard unit of measurement for font size where 1 point (pt) is approximately equal to 1/72 of an inch.</p><p>On iOS, font size is usually measured with points. For example, <code>UIFont</code> in iOS uses point sizes for text.</p><p>Android, however, uses \"scaled pixels\" (sp). To calculate points from scaled pixels, use this formula:</p><p><code>points = scaledPixels / displayDensity</code></p><p>Where <code>scaledPixels</code> is the text size in \"<code>sp</code>\", and displayDensity is the device's screen density.</p>"}}],false]}],["$","article","programmatically-read/determined",{"children":[["$","h3",null,{"id":"programmatically-read/determined","children":"Programmatically read/determined"}],["$","div",null,{"dangerouslySetInnerHTML":{"__html":"<p>This term refers to content that user agents, like assistive technologies, can extract, interpret, and present to users in different modalities.</p>"}}],false]}]]]}],"$undefined",["$","section","r",{"children":[["$","h2",null,{"children":"R"}],[["$","article","reading-sequence",{"children":[["$","h3",null,{"id":"reading-sequence","children":"Reading sequence"}],["$","div",null,{"dangerouslySetInnerHTML":{"__html":"<p>Reading sequence refers to the programmatic order of elements in the UI, as assistive technologies such as screen readers interpret and read them.</p>"}}],false]}],["$","article","real-time-updates",{"children":[["$","h3",null,{"id":"real-time-updates","children":"Real-time updates"}],["$","div",null,{"dangerouslySetInnerHTML":{"__html":"<p>Real-time updates refer to information that dynamically and continuously refreshes and displays changing data or statuses to users. These updates provide current, up-to-the-moment details on a particular event, process, or status relevant to the user's interaction with the application.</p><p>Real-time updates provide users with information that directly impacts their current interaction or experience with the application. For instance, in a delivery app, real-time updates might display the estimated time of arrival (ETA) or the current location of the delivery person.</p><p>A few examples of application types that commonly use real-time updates are public transportation apps, food delivery services, stock market updates, and more.</p><p>In essence, real-time updates in applications serve to keep users informed and engaged by continuously delivering timely and relevant information about ongoing processes or events, enriching the overall user experience.</p>"}}],false]}],["$","article","role",{"children":[["$","h3",null,{"id":"role","children":"Role"}],["$","div",null,{"dangerouslySetInnerHTML":{"__html":"$f"}}],false]}]]]}],["$","section","s",{"children":[["$","h2",null,{"children":"S"}],[["$","article","single-pointer-gestures",{"children":[["$","h3",null,{"id":"single-pointer-gestures","children":"Single-pointer gestures"}],["$","div",null,{"dangerouslySetInnerHTML":{"__html":"<p>Single-pointer gestures are a single point of contact, typically using one-finger interactions like a tap or double-tap that perform actions or trigger specific functionalities within the app's interface. These gestures are often the primary input method for users with a variety of disabilities. Developers must ensure they are responsive and compatible with assistive technologies.</p>"}}],false]}],["$","article","static-media",{"children":[["$","h3",null,{"id":"static-media","children":"Static media"}],["$","div",null,{"dangerouslySetInnerHTML":{"__html":"<p>\"Static media\" refers to non-text content that doesn't change or progress over time (like audio or video tracks would). Examples of static media include images, infographics, diagrams, or other non-text elements that do not rely on a time-based sequence for comprehension.</p><p>See also: <a href='#media'>Media</a>, <a href='#time-based-media'>Time-based media</a>, and <a href='#synchronized-media'>Synchronized media</a></p>"}}],false]}],["$","article","synchronized-media",{"children":[["$","h3",null,{"id":"synchronized-media","children":"Synchronized media"}],["$","div",null,{"dangerouslySetInnerHTML":{"__html":"<p>\"Synchronized media\" refers to a video track with a synchronized corresponding audio track that auditory reflects the actions on the video.</p><p>See also: <a href='#media'>Media</a>, <a href='#static-media'>Static media</a>, and <a href='#time-based-media'>Time-based media</a></p>"}}],false]}]]]}],["$","section","t",{"children":[["$","h2",null,{"children":"T"}],[["$","article","text-blocks",{"children":[["$","h3",null,{"id":"text-blocks","children":"Text blocks"}],["$","div",null,{"dangerouslySetInnerHTML":{"__html":"<p>Text blocks refer to sections or segments of textual content. They typically contain at least three full rows of text in the app's body text font size.</p>"}}],false]}],["$","article","text-alternatives",{"children":[["$","h3",null,{"id":"text-alternatives","children":"Text alternatives"}],["$","div",null,{"dangerouslySetInnerHTML":{"__html":"$10"}}],false]}],["$","article","time-based-media",{"children":[["$","h3",null,{"id":"time-based-media","children":"Time-based media"}],["$","div",null,{"dangerouslySetInnerHTML":{"__html":"<p>\"Time-based media\" refers to non-text content that unfolds or changes over time, such as audio or video files. These media types inherently have a duration and evolve as the content progresses, presenting the information within a specific timeframe.</p><p>See also: <a href='#media'>Media</a>, <a href='#static-media'>Static media</a>, and <a href='#synchronized-media'>Synchronized media</a></p>"}}],false]}],["$","article","time-sensitive-updates",{"children":[["$","h3",null,{"id":"time-sensitive-updates","children":"Time-sensitive updates"}],["$","div",null,{"dangerouslySetInnerHTML":{"__html":"<p>\"Time-sensitive\" updates refer to information or notifications that require immediate attention or action from the user within a specific timeframe. These updates are designed to convey important or critical information with urgency or a limited window of time.</p><p>Time-sensitive updates convey information that requires prompt user action or attention. The information of time-sensitive updates could be related to security alerts, critical reminders, or real-time changes in a situation (e.g., location-based alerts). Time-sensitive notifications are often crucial for the user to maintain an app's service's functionality, security, or timeliness. For example, notifications about account security breaches or transaction verifications are time-sensitive due to their critical nature.</p>"}}],false]}],["$","article","",{"children":[["$","h3",null,{"id":"","children":""}],["$","div",null,{"dangerouslySetInnerHTML":{"__html":"<p></p>"}}],false]}],["$","article","toasts",{"children":[["$","h3",null,{"id":"toasts","children":"Toasts"}],["$","div",null,{"dangerouslySetInnerHTML":{"__html":"<p>\"Toasts\" are small, non-modal messages that provide user feedback, notifications, or alerts. Toast messages are typically displayed for a limited time before they automatically disappear. The fact that Toast messages are non-modal means that they don't require user interaction to dismiss them, and assistive technologies should announce their content without shifting focus to them.</p><p>Toast messages serve as unobtrusive, transient notifications or feedback mechanisms that inform users about specific events, updates, or actions within the app interface without disrupting the user experience.</p>"}}],false]}],["$","article","transcript",{"children":[["$","h3",null,{"id":"transcript","children":"Transcript"}],["$","div",null,{"dangerouslySetInnerHTML":{"__html":"<p>A transcript is a written or typed record of spoken words, dialogue, or text from a specific audio or video file. It represents a textual version of the content spoken or presented within the audio or video recording.</p><p>Unlike captions, transcripts do not provide descriptions of other relevant sounds. Transcripts can be time-indexed but are not synchronized with their associated audio or video tracks.</p>"}}],false]}]]]}],"$undefined","$undefined","$undefined","$undefined","$undefined","$undefined"]}]]}]]}]
